{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e711d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pandas.tseries.offsets import BDay\n",
    "from sklearn.impute import KNNImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mplfinance as mpf\n",
    "import plotly.express as px\n",
    "from scipy.stats import zscore, median_abs_deviation, mstats\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "class StockDataProcessor:\n",
    "    def __init__(self, df=None):\n",
    "        self.df = df.copy() if df is not None else None\n",
    "\n",
    "    # ---------------- Download ----------------1\n",
    "    @staticmethod\n",
    "    def download_stock_data(ticker, period=\"1y\", interval=\"1d\"):\n",
    "        \"\"\"\n",
    "        Download historical stock price data for a given ticker symbol.\n",
    "        This static method fetches stock data from Yahoo Finance using the\n",
    "        `yfinance` library and returns a cleaned pandas DataFrame with\n",
    "        essential columns: date, open, high, low, close, and volume.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ticker : str\n",
    "            The stock ticker symbol.\n",
    "            (\"AAPL\", \"TSLA\",\"MSFT\" etc)\n",
    "\n",
    "        period : str, optional, default \"1y\"\n",
    "            The time span of historical data to retrieve.\n",
    "            [\"1d\", \"5d\", \"1mo\", \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", \"max\"]\n",
    "\n",
    "        interval : str, optional, default \"1d\"\n",
    "            The frequency of data points.\n",
    "            [\"1m\", \"2m\", \"5m\", \"15m\", \"30m\", \"60m\", \"90m\", \"1d\", \"5d\", \"1wk\", \"1mo\", \"3mo\"]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A pandas DataFrame with columns:\n",
    "            - 'date'  : Timestamp of the data point\n",
    "            - 'open'  : Opening price\n",
    "            - 'high'  : Highest price during the interval\n",
    "            - 'low'   : Lowest price during the interval\n",
    "            - 'close' : Closing price\n",
    "            - 'volume': Trading volume\n",
    "        \"\"\"\n",
    "\n",
    "        df = yf.download(ticker, period=period, interval=interval)\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "        df = df.reset_index()[[\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]]\n",
    "        df.columns = df.columns.str.lower()\n",
    "        return df\n",
    "\n",
    "    # ---------------- Fill Missing Dates ----------------2\n",
    "    @staticmethod\n",
    "    def fill_missing_dates(df, date_col='date',break_date = False):\n",
    "        \"\"\"\n",
    "        Fill missing dates in a stock data DataFrame and optionally extract day, month, and year.\n",
    "        This static method identifies missing or NaN values in the date column of a DataFrame\n",
    "        and fills them using **business day offsets** (pandas BDay). It ensures that all rows\n",
    "        have valid dates, preserving chronological order. Optionally, it can also split the\n",
    "        date into separate day, month, and year columns.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            The input DataFrame containing stock data, including a date column.\n",
    "\n",
    "        date_col : str, optional, default 'date'\n",
    "            The name of the column containing dates. The column should be parseable by\n",
    "            `pd.to_datetime()`.\n",
    "\n",
    "        break_date : bool, optional, default False\n",
    "            If True, creates three new columns in the DataFrame: \n",
    "            - 'day'   : day of the month\n",
    "            - 'month' : month number\n",
    "            - 'year'  : year\n",
    "            If False, the original date column is retained as-is.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            The DataFrame with missing dates filled. If `break_date` is True, the DataFrame\n",
    "            also includes 'day', 'month', and 'year' columns.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - Missing dates are filled using the previous valid date plus the number of business days \n",
    "        to the missing row. If no previous date exists, the next valid date is used minus the \n",
    "        appropriate number of business days.\n",
    "        - If all surrounding dates are missing, the current date (`pd.Timestamp.today()`) is used.\n",
    "        - The method sorts the DataFrame by its index before processing.\n",
    "        \"\"\"\n",
    "\n",
    "        df = df.sort_index()  \n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "        nan_idx = df[df[date_col].isna()].index\n",
    "\n",
    "        for idx in nan_idx:\n",
    "            prev_idx = idx - 1\n",
    "            while prev_idx >= 0 and pd.isna(df.at[prev_idx, date_col]):\n",
    "                prev_idx -= 1\n",
    "\n",
    "            next_idx = idx + 1\n",
    "            while next_idx < len(df) and pd.isna(df.at[next_idx, date_col]):\n",
    "                next_idx += 1\n",
    "\n",
    "            if prev_idx >= 0:\n",
    "                prev_date = df.at[prev_idx, date_col]\n",
    "                df.at[idx, date_col] = prev_date + BDay(idx - prev_idx)\n",
    "            elif next_idx < len(df):\n",
    "                next_date = df.at[next_idx, date_col]\n",
    "                df.at[idx, date_col] = next_date - BDay(next_idx - idx)\n",
    "            else:\n",
    "                df.at[idx, date_col] = pd.Timestamp.today()\n",
    "\n",
    "        if(break_date==True):\n",
    "            df['day'] = df[date_col].dt.day\n",
    "            df['month'] = df[date_col].dt.month\n",
    "            df['year'] = df[date_col].dt.year\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # ---------------- Fill NaN Advanced ----------------3\n",
    "    @staticmethod\n",
    "    def markov_impute(series, n_bins=20, strategy=\"mode\"):\n",
    "        s = series.copy()\n",
    "\n",
    "        notnull = s.dropna()\n",
    "        bins = np.linspace(notnull.min(), notnull.max(), n_bins + 1)\n",
    "        states = np.digitize(notnull, bins) - 1\n",
    "        states = np.clip(states, 0, n_bins - 1)\n",
    "\n",
    "        trans_mat = np.zeros((n_bins, n_bins))\n",
    "        for i in range(len(states) - 1):\n",
    "            trans_mat[states[i], states[i + 1]] += 1\n",
    "\n",
    "        row_sums = trans_mat.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        P = trans_mat / row_sums\n",
    "\n",
    "        for idx in s.index[s.isna()]:\n",
    "            prev_idx = s.index[s.index.get_loc(idx) - 1] if s.index.get_loc(idx) > 0 else None\n",
    "            if prev_idx is None or pd.isna(s[prev_idx]):\n",
    "                s.at[idx] = notnull.mean()\n",
    "                continue\n",
    "\n",
    "            prev_val = s[prev_idx]\n",
    "            prev_state = np.digitize(prev_val, bins) - 1\n",
    "            prev_state = np.clip(prev_state, 0, n_bins - 1)\n",
    "\n",
    "            if strategy == \"mode\":\n",
    "                next_state = np.argmax(P[prev_state])\n",
    "            else:\n",
    "                next_state = np.random.choice(np.arange(n_bins), p=P[prev_state])\n",
    "\n",
    "            s.at[idx] = (bins[next_state] + bins[next_state + 1]) / 2\n",
    "\n",
    "        return s\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_nan_advanced(df, col_tech_map):\n",
    "        \"\"\"\n",
    "        Fill missing values in a DataFrame using advanced, column-specific imputation techniques.\n",
    "        This static method allows flexible handling of NaN values in a DataFrame. Each column\n",
    "        can have one or more imputation techniques applied sequentially. Techniques can be\n",
    "        statistical, interpolation-based, rolling/window-based, machine-learning-based, or \n",
    "        smoothing-based.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            The input DataFrame containing numeric or categorical columns with missing values.\n",
    "\n",
    "        col_tech_map : dict\n",
    "            A dictionary mapping column names to a list of techniques and optional parameters.\n",
    "            Each column key maps to a list of tuples, where each tuple is:\n",
    "                (technique_name: str, params: dict)\n",
    "\n",
    "            Example format:\n",
    "            {\n",
    "                'column1': [('mean', {}), ('ffill', {})],\n",
    "                'column2': [('knn', {'n_neighbors': 5})],\n",
    "                'column3': [('drop', {})]\n",
    "            }\n",
    "\n",
    "            Supported techniques and example format:\n",
    "\n",
    "            - 'drop'             : [('drop', {})]\n",
    "            - 'mean'             : [('mean', {})]\n",
    "            - 'median'           : [('median', {})]\n",
    "            - 'mode'             : [('mode', {})]\n",
    "            - 'ffill'            : [('ffill', {})]\n",
    "            - 'bfill'            : [('bfill', {})]\n",
    "            - 'sma' / 'rolling'  : [('sma', {'window': 14})]  # 'window' optional, default 14\n",
    "            - 'ema'              : [('ema', {'alpha': 0.3})]  # 'alpha' optional, default 0.3\n",
    "            - 'linear'           : [('linear', {})]\n",
    "            - 'quadratic'        : [('quadratic', {})]\n",
    "            - 'cubic'            : [('cubic', {})]\n",
    "            - 'knn'              : [('knn', {'n_neighbors': 3})]  # default n_neighbors=3\n",
    "            - 'markov'           : [('markov', {})]\n",
    "            - 'weighted_combo'   : [('weighted_combo', {'window': 14, 'alpha': 0.3})]\n",
    "            - 'kalman'           : [('kalman', {})]\n",
    "\n",
    "            Full example dictionary:\n",
    "\n",
    "            col_tech_map_examples = {\n",
    "                'column1': [('drop', {})],\n",
    "                'column2': [('mean', {})],\n",
    "                'column3': [('median', {})],\n",
    "                'column4': [('mode', {})],\n",
    "                'column5': [('ffill', {})],\n",
    "                'column6': [('bfill', {})],\n",
    "                'column7': [('sma', {'window': 10})],\n",
    "                'column8': [('ema', {'alpha': 0.2})],\n",
    "                'column9': [('linear', {})],\n",
    "                'column10': [('quadratic', {})],\n",
    "                'column11': [('cubic', {})],\n",
    "                'column12': [('knn', {'n_neighbors': 5})],\n",
    "                'column13': [('markov', {})],\n",
    "                'column14': [('weighted_combo', {'window': 14, 'alpha': 0.3})],\n",
    "                'column15': [('kalman', {})]\n",
    "            }\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A copy of the input DataFrame with missing values filled according to the\n",
    "            specified techniques. The original DataFrame remains unchanged.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - 'drop' is applied first for each column, then other techniques are applied in order.\n",
    "        - Multiple techniques can be applied sequentially per column.\n",
    "        - Non-numeric columns are skipped for numeric-only techniques like 'knn', 'kalman', or 'weighted_combo'.\n",
    "        - Interpolation methods fill in both forward and backward directions.\n",
    "        - Weighted combo computes 0.5 * SMA + 0.5 * EMA for filling missing values.\n",
    "        \"\"\"\n",
    "\n",
    "        df_filled = df.copy()\n",
    "        \n",
    "        drop_cols = [col for col, techs in col_tech_map.items() if any(t[0]=='drop' for t in techs)]\n",
    "        if drop_cols:\n",
    "            df_filled = df_filled.dropna(subset=drop_cols)\n",
    "        \n",
    "        for col, techs in col_tech_map.items():\n",
    "            for tech, params in techs:\n",
    "                if tech == \"drop\":\n",
    "                    continue  \n",
    "\n",
    "                if tech == \"mean\":\n",
    "                    df_filled[col] = df_filled[col].fillna(df_filled[col].mean())\n",
    "\n",
    "                elif tech == \"median\":\n",
    "                    df_filled[col] = df_filled[col].fillna(df_filled[col].median())\n",
    "\n",
    "                elif tech == \"mode\":\n",
    "                    df_filled[col] = df_filled[col].fillna(df_filled[col].mode()[0])\n",
    "\n",
    "                elif tech == \"ffill\":\n",
    "                    df_filled[col] = df_filled[col].fillna(method='ffill')\n",
    "\n",
    "                elif tech == \"bfill\":\n",
    "                    df_filled[col] = df_filled[col].fillna(method='bfill')\n",
    "\n",
    "                elif tech == \"sma\" or tech == \"rolling\":\n",
    "                    window = params.get('window', 14)\n",
    "                    df_filled[col] = df_filled[col].fillna(df_filled[col].rolling(window=window, min_periods=1).mean())\n",
    "\n",
    "                elif tech == \"ema\":\n",
    "                    alpha = params.get('alpha', 0.3)\n",
    "                    df_filled[col] = df_filled[col].fillna(df_filled[col].ewm(alpha=alpha, adjust=False).mean())\n",
    "\n",
    "                elif tech in [\"linear\", \"quadratic\", \"cubic\"]:\n",
    "                    df_filled[col] = df_filled[col].interpolate(method=tech, limit_direction='both')\n",
    "\n",
    "                elif tech == \"knn\":\n",
    "                    n_neighbors = params.get('n_neighbors', 3)\n",
    "\n",
    "                    numeric_cols = df_filled.select_dtypes(include=['number']).columns\n",
    "                    if col not in numeric_cols:\n",
    "                        continue  \n",
    "\n",
    "                    if len(numeric_cols) > 1:\n",
    "                        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "                        df_filled_numeric = pd.DataFrame(\n",
    "                            imputer.fit_transform(df_filled[numeric_cols]),\n",
    "                            columns=numeric_cols,\n",
    "                            index=df_filled.index\n",
    "                        )\n",
    "                        df_filled[col] = df_filled_numeric[col]\n",
    "                    else:\n",
    "                        if df_filled[col].dropna().empty:\n",
    "                            df_filled[col] = 0  \n",
    "                        else:\n",
    "                            df_filled[col] = df_filled[col].fillna(df_filled[col].mean())\n",
    "\n",
    "\n",
    "                elif tech == \"markov\":\n",
    "                    df_filled[col] = StockDataProcessor.markov_impute(df_filled[col], n_bins=20, strategy=\"mode\")\n",
    "\n",
    "                elif tech == \"weighted_combo\":\n",
    "                    window = params.get('window', 14)\n",
    "                    alpha = params.get('alpha', 0.3)\n",
    "                    filled_df = 0.5*df_filled[col].rolling(window=window, min_periods=1).mean() + \\\n",
    "                                0.5*df_filled[col].ewm(alpha=alpha, adjust=False).mean()\n",
    "                    df_filled[col] = df_filled[col].fillna(filled_df)\n",
    "\n",
    "                elif tech == \"kalman\":\n",
    "                    series = df_filled[col].copy()\n",
    "                    if series.dropna().empty:\n",
    "                        continue\n",
    "\n",
    "                    values = series.interpolate(limit_direction=\"both\").values\n",
    "\n",
    "                    kf = KalmanFilter(\n",
    "                        transition_matrices=[1],\n",
    "                        observation_matrices=[1],\n",
    "                        initial_state_mean=values[0],\n",
    "                        initial_state_covariance=1,\n",
    "                        transition_covariance=0.01,\n",
    "                        observation_covariance=1\n",
    "                    )\n",
    "\n",
    "                    state_means, _ = kf.smooth(values)\n",
    "                    df_filled[col] = pd.Series(state_means.flatten(), index=series.index)\n",
    " \n",
    "                else:\n",
    "                    raise ValueError(f\"Technique '{tech}' not recognized\")\n",
    "        \n",
    "        return df_filled\n",
    "\n",
    "    #----------------- Plot Graphs --------------------4\n",
    "    @staticmethod\n",
    "    def plot_graph(df, columns, graph_type, size=(10,6), color='blue', stacked=False):\n",
    "        \"\"\"\n",
    "        Plot various types of graphs from a DataFrame for visualization.\n",
    "        This static method supports multiple graph types using matplotlib, seaborn,\n",
    "        mplfinance, and plotly. It handles common chart types for exploratory data\n",
    "        analysis or financial visualization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            The input DataFrame containing the data to plot.\n",
    "\n",
    "        columns : list of str\n",
    "            List of column names to use in the plot. Column type requirements vary by `graph_type`:\n",
    "\n",
    "            - 'line'          : 2 columns [x (numeric), y (numeric)]\n",
    "            - 'scatter'       : 2 columns [x (numeric), y (numeric)]\n",
    "            - 'bar'           : 1 or 2 columns\n",
    "                                - 1 column: categorical or numeric counts\n",
    "                                - 2 columns: x (categorical or numeric), y (numeric)\n",
    "            - 'hist'          : 1 column [numeric]\n",
    "            - 'box'           : 1 column [numeric]\n",
    "            - 'violin'        : 1 column [numeric]\n",
    "            - 'pairplot'      : >=2 columns [all numeric or categorical encoded as numeric]\n",
    "            - 'area'          : >=2 columns [x (numeric), y series (numeric)]\n",
    "            - 'stacked_area', 'stream': >=2 columns [x (numeric), multiple y series (numeric)]\n",
    "            - 'pie'           : 1 or 2 columns\n",
    "                                - 1 column: categorical counts\n",
    "                                - 2 columns: category (categorical), value (numeric)\n",
    "            - 'waterfall'     : 2 columns [category (categorical), value (numeric)]\n",
    "            - 'treemap'       : 2 columns [category (categorical), value (numeric)]\n",
    "            - 'sunburst'      : >=2 columns [levels (categorical), value (numeric)]\n",
    "            - 'choropleth'    : 2 columns [region (categorical/ISO-3), value (numeric)]\n",
    "            - 'candlestick'   : 4+ columns ['open','high','low','close'] and 'date' as index (numeric prices)\n",
    "\n",
    "        graph_type : str\n",
    "            Type of graph to generate. Supported types: see above.\n",
    "\n",
    "        size : tuple, optional, default (10,6)\n",
    "            Figure size in inches (width, height).\n",
    "\n",
    "        color : str or list, optional, default 'blue'\n",
    "            Color specification for the plot. Can be a single color or a list of colors\n",
    "            for multi-series plots. For plotly charts, used as color scale.\n",
    "\n",
    "        stacked : bool, optional, default False\n",
    "            Only relevant for area/stacked_area/stream plots. If True, series are stacked.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            The function directly displays the plot and does not return a value.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - Matplotlib is used for standard line, bar, scatter, histogram, area, waterfall plots.\n",
    "        - Seaborn is used for box, violin, and pairplot visualizations.\n",
    "        - mplfinance is used for candlestick charts.\n",
    "        - Plotly is used for treemap, sunburst, and choropleth maps.\n",
    "        - Users must ensure required columns exist in the DataFrame and have the correct type; otherwise, a ValueError is raised.\n",
    "        - The method automatically labels axes and titles for clarity.\n",
    "        \"\"\"\n",
    "\n",
    "        plt.figure(figsize=size)\n",
    "\n",
    "        if graph_type == 'line':\n",
    "            if len(columns) != 2:\n",
    "                raise ValueError(\"Line plot requires 2 columns: x and y\")\n",
    "            plt.plot(df[columns[0]], df[columns[1]], color=color)\n",
    "            plt.xlabel(columns[0])\n",
    "            plt.ylabel(columns[1])\n",
    "            plt.title(f\"Line Plot: {columns[1]} vs {columns[0]}\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'bar':\n",
    "            if len(columns) == 1:\n",
    "                df[columns[0]].value_counts().plot(kind='bar', color=color)\n",
    "            elif len(columns) == 2:\n",
    "                plt.bar(df[columns[0]], df[columns[1]], color=color)\n",
    "            else:\n",
    "                raise ValueError(\"Bar plot requires 1 or 2 columns\")\n",
    "            plt.title(f\"Bar Plot\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'hist':\n",
    "            if len(columns) != 1:\n",
    "                raise ValueError(\"Histogram requires 1 column\")\n",
    "            plt.hist(df[columns[0]], color=color, bins=20)\n",
    "            plt.title(f\"Histogram: {columns[0]}\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'scatter':\n",
    "            if len(columns) != 2:\n",
    "                raise ValueError(\"Scatter plot requires 2 columns: x and y\")\n",
    "            plt.scatter(df[columns[0]], df[columns[1]], color=color)\n",
    "            plt.xlabel(columns[0])\n",
    "            plt.ylabel(columns[1])\n",
    "            plt.title(f\"Scatter Plot: {columns[1]} vs {columns[0]}\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'box':\n",
    "            if len(columns) != 1:\n",
    "                raise ValueError(\"Box plot requires 1 column\")\n",
    "            sns.boxplot(y=df[columns[0]], color=color)\n",
    "            plt.title(f\"Box Plot: {columns[0]}\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'violin':\n",
    "            if len(columns) != 1:\n",
    "                raise ValueError(\"Violin plot requires 1 column\")\n",
    "            sns.violinplot(y=df[columns[0]], color=color)\n",
    "            plt.title(f\"Violin Plot: {columns[0]}\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'pairplot':\n",
    "            if len(columns) < 2:\n",
    "                raise ValueError(\"Pairplot requires at least 2 columns\")\n",
    "            sns.pairplot(df[columns], palette=color)\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'candlestick':\n",
    "            if not all(c in df.columns for c in ['open','high','low','close']):\n",
    "                raise ValueError(\"Candlestick plot requires columns: 'open','high','low','close'\")\n",
    "            mpf.plot(df.set_index('date'), type='candle', style='charles', figsize=size)\n",
    "\n",
    "        elif graph_type == 'area':\n",
    "            if len(columns) < 2:\n",
    "                raise ValueError(\"Area plot requires at least 2 columns: x + y series\")\n",
    "            if stacked:\n",
    "                plt.stackplot(df[columns[0]], df[columns[1:]], labels=columns[1:], colors=color if isinstance(color,list) else None)\n",
    "            else:\n",
    "                for col in columns[1:]:\n",
    "                    plt.plot(df[columns[0]], df[col], label=col, color=color)\n",
    "            plt.xlabel(columns[0])\n",
    "            plt.title(\"Area Plot\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'pie':\n",
    "            if len(columns) == 1:\n",
    "                df[columns[0]].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=color if isinstance(color,list) else None)\n",
    "            elif len(columns) == 2:\n",
    "                df.groupby(columns[0])[columns[1]].sum().plot(kind='pie', autopct='%1.1f%%', colors=color if isinstance(color,list) else None)\n",
    "            else:\n",
    "                raise ValueError(\"Pie plot requires 1 or 2 columns\")\n",
    "            plt.title(\"Pie Chart\")\n",
    "            plt.ylabel('')\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'treemap':\n",
    "            if len(columns) != 2:\n",
    "                raise ValueError(\"Treemap requires 2 columns: category + value\")\n",
    "            fig = px.treemap(df, path=[columns[0]], values=columns[1], color=columns[1], color_continuous_scale=color)\n",
    "            fig.show()\n",
    "\n",
    "        elif graph_type == 'sunburst':\n",
    "            if len(columns) < 2:\n",
    "                raise ValueError(\"Sunburst requires at least 2 columns: levels + value\")\n",
    "            fig = px.sunburst(df, path=columns[:-1], values=columns[-1], color=columns[-1], color_continuous_scale=color)\n",
    "            fig.show()\n",
    "\n",
    "        elif graph_type == 'stacked_area' or graph_type == 'stream':\n",
    "            if len(columns) < 2:\n",
    "                raise ValueError(\"Stacked/Stream plot requires at least 2 columns: x + multiple series\")\n",
    "            plt.stackplot(df[columns[0]], df[columns[1:]], labels=columns[1:], colors=color if isinstance(color,list) else None)\n",
    "            plt.xlabel(columns[0])\n",
    "            plt.title(f\"{graph_type.replace('_',' ').title()} Plot\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'waterfall':\n",
    "            if len(columns) != 2:\n",
    "                raise ValueError(\"Waterfall plot requires 2 columns: category + value\")\n",
    "            cumulative = df[columns[1]].cumsum()\n",
    "            colors = ['green' if v >= 0 else 'red' for v in df[columns[1]]]\n",
    "            plt.bar(df[columns[0]], df[columns[1]], color=colors)\n",
    "            plt.plot(df[columns[0]], cumulative, color='blue', marker='o', linestyle='--')\n",
    "            plt.title(\"Waterfall Chart\")\n",
    "            plt.show()\n",
    "\n",
    "        elif graph_type == 'choropleth':\n",
    "            if len(columns) != 2:\n",
    "                raise ValueError(\"Choropleth requires 2 columns: region + value\")\n",
    "            fig = px.choropleth(df, locations=columns[0], color=columns[1], color_continuous_scale=color, locationmode='ISO-3')\n",
    "            fig.show()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Graph type '{graph_type}' not recognized\")\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------- Detect Outliers ----------------5\n",
    "    @staticmethod\n",
    "    def detect_outliers_advanced(df, numeric_cols, z_thresh=3, mod_z_thresh=3.5, rolling_window=5, price_change_thresh=0.05, plot_graphs=True,combine='union',vote_thresh=None):\n",
    "        \"\"\"\n",
    "        Detect outliers in numeric columns of a DataFrame using multiple statistical and rolling methods.\n",
    "        This static method applies several techniques to identify outliers in numeric columns. \n",
    "        Users can choose to combine the results using union, intersection, or a voting threshold.\n",
    "        Optionally, it can generate visualizations for each column.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Input DataFrame containing numeric columns for outlier detection. A 'date' column\n",
    "            can be included for scatter/time-series plots.\n",
    "\n",
    "        numeric_cols : list of str\n",
    "            List of numeric column names to check for outliers.\n",
    "\n",
    "        z_thresh : float, optional, default 3\n",
    "            Threshold for standard Z-score method. Points with |Z| > z_thresh are considered outliers.\n",
    "\n",
    "        mod_z_thresh : float, optional, default 3.5\n",
    "            Threshold for modified Z-score method (based on median and MAD). Points with |modified Z| > mod_z_thresh are outliers.\n",
    "\n",
    "        rolling_window : int, optional, default 5\n",
    "            Window size for rolling mean and rolling standard deviation outlier detection.\n",
    "\n",
    "        price_change_thresh : float, optional, default 0.05\n",
    "            Threshold for detecting outliers based on absolute percent change between consecutive rows.\n",
    "\n",
    "        plot_graphs : bool, optional, default True\n",
    "            If True, generates boxplot, histogram/KDE, scatter/time series (if 'date' exists), and violin plot for each column.\n",
    "\n",
    "        combine : str, optional, default 'union'\n",
    "            Method to combine outlier indices from different techniques:\n",
    "            - 'union': combine all detected indices\n",
    "            - 'intersection': only keep indices detected by all methods\n",
    "\n",
    "        vote_thresh : int, optional, default None\n",
    "            If specified, only indices detected by at least `vote_thresh` methods are considered outliers.\n",
    "            Overrides `combine` if provided.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary structured as:\n",
    "            {\n",
    "                'column_name': {\n",
    "                    'per_method': {\n",
    "                        'z_score': set(indices),\n",
    "                        'modified_z': set(indices),\n",
    "                        'iqr': set(indices),\n",
    "                        'rolling': set(indices),\n",
    "                        'price_change': set(indices),\n",
    "                        'returns_z': set(indices),\n",
    "                        'cusum': set(indices)\n",
    "                    },\n",
    "                    'combined': set(indices)\n",
    "                },\n",
    "                ...\n",
    "            }\n",
    "            - 'per_method': indices detected by each individual method\n",
    "            - 'combined': final set of outlier indices after union/intersection/vote_thresh\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Outlier detection methods included:\n",
    "        1. Z-score: standard score using mean and std deviation\n",
    "        2. Modified Z-score: robust score using median and MAD\n",
    "        3. IQR: points outside 1.5*IQR from Q1 and Q3\n",
    "        4. Rolling: points outside 3*rolling_std from rolling_mean\n",
    "        5. Price Change: absolute percentage change > price_change_thresh\n",
    "        6. Returns Z-score: Z-score on percent changes\n",
    "        7. CUSUM: cumulative sum method detecting sudden shifts\n",
    "\n",
    "        Visualizations (if plot_graphs=True):\n",
    "        - Boxplot\n",
    "        - Histogram / KDE\n",
    "        - Scatter / Time Series (if 'date' exists)\n",
    "        - Violin plot\n",
    "        \"\"\"\n",
    "\n",
    "        outliers = {col:{} for col in numeric_cols}\n",
    "        for col in numeric_cols:\n",
    "            series = df[col].dropna()\n",
    "            if series.empty:\n",
    "                continue\n",
    "            \n",
    "            method_outliers = {}\n",
    "            \n",
    "            z_scores = zscore(series)\n",
    "            method_outliers['z_score'] = set(series.index[(z_scores > z_thresh) | (z_scores < -z_thresh)].tolist())\n",
    "            \n",
    "            med = series.median()\n",
    "            mad = median_abs_deviation(series, scale='normal')\n",
    "            mod_z = 0.6745 * (series - med) / mad\n",
    "            method_outliers['modified_z'] = set(series.index[(mod_z > mod_z_thresh) | (mod_z < -mod_z_thresh)].tolist())\n",
    "            \n",
    "            Q1 = series.quantile(0.25)\n",
    "            Q3 = series.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            method_outliers['iqr'] = set(series.index[(series < Q1 - 1.5*IQR) | (series > Q3 + 1.5*IQR)].tolist())\n",
    "            \n",
    "            roll_mean = series.rolling(rolling_window, min_periods=1).mean()\n",
    "            roll_std = series.rolling(rolling_window, min_periods=1).std()\n",
    "            method_outliers['rolling'] = set(series.index[(series > roll_mean + 3*roll_std) | (series < roll_mean - 3*roll_std)].tolist())\n",
    "            \n",
    "            returns = series.pct_change()\n",
    "            method_outliers['price_change'] = set(returns.index[returns.abs() > price_change_thresh].tolist())\n",
    "            \n",
    "            returns_no_na = returns.dropna()\n",
    "            if not returns_no_na.empty:\n",
    "                returns_z = zscore(returns_no_na)\n",
    "                method_outliers['returns_z'] = set(returns_no_na.index[(returns_z > z_thresh) | (returns_z < -z_thresh)].tolist())\n",
    "            else:\n",
    "                method_outliers['returns_z'] = set()\n",
    "            \n",
    "            mean_val = series.mean()\n",
    "            cusum_pos, cusum_neg = 0, 0\n",
    "            cusum_idx = []\n",
    "            for idx, x in zip(series.index, series):\n",
    "                cusum_pos = max(0, cusum_pos + x - mean_val)\n",
    "                cusum_neg = min(0, cusum_neg + x - mean_val)\n",
    "                if cusum_pos > 3*series.std() or abs(cusum_neg) > 3*series.std():\n",
    "                    cusum_idx.append(idx)\n",
    "                    cusum_pos, cusum_neg = 0,0\n",
    "            method_outliers['cusum'] = set(cusum_idx)\n",
    "            \n",
    "            if vote_thresh is not None:\n",
    "                all_indices = [idx for s in method_outliers.values() for idx in s]\n",
    "                from collections import Counter\n",
    "                counts = Counter(all_indices)\n",
    "                outliers[col]['combined'] = set(idx for idx, c in counts.items() if c >= vote_thresh)\n",
    "            else:\n",
    "                if combine == 'union':\n",
    "                    outliers[col]['combined'] = set().union(*method_outliers.values())\n",
    "                elif combine == 'intersection':\n",
    "                    if method_outliers.values():\n",
    "                        outliers[col]['combined'] = set.intersection(*method_outliers.values())\n",
    "                    else:\n",
    "                        outliers[col]['combined'] = set()\n",
    "                else:\n",
    "                    raise ValueError(\"combine must be 'union' or 'intersection'\")\n",
    "            \n",
    "            outliers[col]['per_method'] = method_outliers\n",
    "            \n",
    "            if plot_graphs and not series.empty:\n",
    "                plt.figure(figsize=(12,4))\n",
    "                sns.boxplot(y=series)\n",
    "                plt.title(f\"Boxplot of {col}\")\n",
    "                plt.show()\n",
    "                \n",
    "                plt.figure(figsize=(12,4))\n",
    "                sns.histplot(series, kde=True, color='orange', bins=20)\n",
    "                plt.title(f\"Histogram / KDE of {col}\")\n",
    "                plt.show()\n",
    "                \n",
    "                plt.figure(figsize=(12,4))\n",
    "                if 'date' in df.columns:\n",
    "                    plt.scatter(df['date'], df[col], color='green')\n",
    "                    plt.title(f\"Scatter / Time Series Plot of {col}\")\n",
    "                    plt.show()\n",
    "                \n",
    "                plt.figure(figsize=(12,4))\n",
    "                sns.violinplot(y=series, color='purple')\n",
    "                plt.title(f\"Violin Plot of {col}\")\n",
    "                plt.show()\n",
    "                \n",
    "        return outliers\n",
    "\n",
    "    # ---------------- Treat Outliers ----------------6\n",
    "    @staticmethod\n",
    "    def treat_outliers(df, outlier_results, treatment_map):\n",
    "        \"\"\"\n",
    "        Treat outliers in a DataFrame based on previously detected outlier indices.\n",
    "        This static method applies various treatments to handle outliers in numeric\n",
    "        columns. Users can choose from deletion, capping, replacement, transformations,\n",
    "        smoothing, and imputation techniques. Treatments are specified per column using\n",
    "        a `treatment_map`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Input DataFrame containing numeric columns to treat outliers.\n",
    "\n",
    "        outlier_results : dict\n",
    "            Dictionary of outlier indices as returned by `detect_outliers_advanced`.\n",
    "            Structure:\n",
    "            {\n",
    "                'column_name': {\n",
    "                    'per_method': {...},\n",
    "                    'combined': set(indices)\n",
    "                },\n",
    "                ...\n",
    "            }\n",
    "\n",
    "        treatment_map : dict\n",
    "            Dictionary specifying how to treat outliers per column. Each column maps to\n",
    "            a list of tuples: (method_name: str, params: dict)\n",
    "\n",
    "            Supported methods and example formats:\n",
    "\n",
    "            - \"delete\"          : [('delete', {})]  \n",
    "            Deletes rows containing outliers.\n",
    "\n",
    "            - \"winsorize\" / \"cap\" : [('winsorize', {'lower':0.01, 'upper':0.99})]  \n",
    "            Limits extreme values to specified quantiles (lower, upper).\n",
    "\n",
    "            - \"median_replace\"  : [('median_replace', {})]  \n",
    "            Replaces outliers with the median of the column.\n",
    "\n",
    "            - \"mean_cap\"        : [('mean_cap', {'k':3})]  \n",
    "            Clips outliers to mean Â± k*std deviation.\n",
    "\n",
    "            - \"log_transform\"   : [('log_transform', {})]  \n",
    "            Applies log(1 + x) transform; negative values clipped to 0.\n",
    "\n",
    "            - \"sqrt_transform\"  : [('sqrt_transform', {})]  \n",
    "            Applies square root transform; negative values clipped to 0.\n",
    "\n",
    "            - \"boxcox\"          : [('boxcox', {})]  \n",
    "            Applies Box-Cox transform; values must be positive.\n",
    "\n",
    "            - \"robust_flag\"     : [('robust_flag', {})]  \n",
    "            Adds a new column `<col>_is_outlier` with 1 for outliers, 0 otherwise.\n",
    "\n",
    "            - \"interpolate\" / \"interpolate_method\" : [('interpolate_linear', {})]  \n",
    "            Interpolates outliers using linear, quadratic, cubic, etc.  \n",
    "            - Params: {'method': 'linear'} (optional if using method suffix)\n",
    "\n",
    "            - \"rolling_mean\"    : [('rolling_mean', {'window':5})]  \n",
    "            Replaces values with rolling mean over specified window.\n",
    "\n",
    "            - \"rolling_median\"  : [('rolling_median', {'window':5})]  \n",
    "            Replaces values with rolling median over specified window.\n",
    "\n",
    "            - \"ema_smooth\"      : [('ema_smooth', {'alpha':0.3})]  \n",
    "            Smooths series using exponential moving average with given alpha.\n",
    "\n",
    "            - \"kalman\"          : [('kalman', {})]  \n",
    "            Smooths values using Kalman filter.\n",
    "\n",
    "            - \"markov_prev\"     : [('markov_prev', {})]  \n",
    "            Replaces outlier with previous non-outlier value.\n",
    "\n",
    "            - \"markov_avg\"      : [('markov_avg', {})]  \n",
    "            Replaces outlier with average of previous and next values.\n",
    "\n",
    "            Notes:\n",
    "            - Multiple methods can be applied sequentially per column.\n",
    "            - Parameters are optional; defaults will be used if not provided.\n",
    "            - Methods like \"kalman\", \"rolling_mean\", and \"rolling_median\" require numeric data.\n",
    "            - Unknown method names will raise ValueError.\n",
    "\n",
    "            Example treatment_map:\n",
    "            treatment_map = {\n",
    "                'price': [('winsorize', {'lower':0.01, 'upper':0.99}), ('log_transform', {})],\n",
    "                'volume': [('median_replace', {})],\n",
    "                'returns': [('ema_smooth', {'alpha':0.2})]\n",
    "            }\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A copy of the input DataFrame with outliers treated according to the\n",
    "            specified methods. The original DataFrame remains unchanged.\n",
    "        \"\"\"\n",
    "        \n",
    "        df_treated = df.copy()\n",
    "        \n",
    "        for col, methods in treatment_map.items():\n",
    "            if col not in outlier_results:\n",
    "                continue\n",
    "            \n",
    "            outlier_idx = list(outlier_results[col]['combined'])\n",
    "            \n",
    "            for method, params in methods:\n",
    "                if method == \"delete\":\n",
    "                    df_treated = df_treated.drop(index=outlier_idx)\n",
    "                \n",
    "                elif method in [\"winsorize\", \"cap\"]:\n",
    "                    from scipy.stats import mstats\n",
    "                    lower = params.get('lower', 0.01)\n",
    "                    upper = params.get('upper', 0.99)\n",
    "                    df_treated[col] = mstats.winsorize(df_treated[col], limits=(lower, 1-upper))\n",
    "                \n",
    "                elif method == \"median_replace\":\n",
    "                    df_treated.loc[outlier_idx, col] = df_treated[col].median()\n",
    "                \n",
    "                elif method == \"mean_cap\":\n",
    "                    k = params.get('k', 3)\n",
    "                    mean_val = df_treated[col].mean()\n",
    "                    std_val = df_treated[col].std()\n",
    "                    lower, upper = mean_val - k*std_val, mean_val + k*std_val\n",
    "                    df_treated.loc[outlier_idx, col] = np.clip(df_treated.loc[outlier_idx, col], lower, upper)\n",
    "                \n",
    "                elif method == \"log_transform\":\n",
    "                    df_treated[col] = np.log1p(df_treated[col].clip(lower=0))\n",
    "                \n",
    "                elif method == \"sqrt_transform\":\n",
    "                    df_treated[col] = np.sqrt(df_treated[col].clip(lower=0))\n",
    "                \n",
    "                elif method == \"boxcox\":\n",
    "                    from scipy.stats import boxcox\n",
    "                    positive_vals = df_treated[col].clip(lower=1e-6)\n",
    "                    df_treated[col], _ = boxcox(positive_vals)\n",
    "                \n",
    "                elif method == \"robust_flag\":\n",
    "                    df_treated[col + \"_is_outlier\"] = 0\n",
    "                    df_treated.loc[outlier_idx, col + \"_is_outlier\"] = 1\n",
    "                \n",
    "                elif method.startswith(\"interpolate\"):\n",
    "                    interp_type = method.split(\"_\")[1] if \"_\" in method else params.get('method','linear')\n",
    "                    df_treated[col] = df_treated[col].interpolate(method=interp_type)\n",
    "                \n",
    "                elif method == \"rolling_mean\":\n",
    "                    window = params.get('window', 5)\n",
    "                    df_treated[col] = df_treated[col].rolling(window, min_periods=1).mean()\n",
    "                \n",
    "                elif method == \"rolling_median\":\n",
    "                    window = params.get('window', 5)\n",
    "                    df_treated[col] = df_treated[col].rolling(window, min_periods=1).median()\n",
    "                \n",
    "                elif method == \"ema_smooth\":\n",
    "                    alpha = params.get('alpha', 0.3)\n",
    "                    df_treated[col] = df_treated[col].ewm(alpha=alpha, adjust=False).mean()\n",
    "                \n",
    "                elif method == \"kalman\":\n",
    "                    series = df_treated[col].copy()\n",
    "                    if series.dropna().empty:\n",
    "                        continue\n",
    "                    values = series.interpolate(limit_direction=\"both\").values\n",
    "                    kf = KalmanFilter(\n",
    "                        transition_matrices=[1],\n",
    "                        observation_matrices=[1],\n",
    "                        initial_state_mean=values[0],\n",
    "                        initial_state_covariance=1,\n",
    "                        transition_covariance=0.01,\n",
    "                        observation_covariance=1\n",
    "                    )\n",
    "                    state_means, _ = kf.smooth(values)\n",
    "                    df_treated[col] = pd.Series(state_means.flatten(), index=series.index)\n",
    "                \n",
    "                elif method == \"markov_prev\":\n",
    "                    df_treated.loc[outlier_idx, col] = df_treated[col].shift(1).loc[outlier_idx]\n",
    "                \n",
    "                elif method == \"markov_avg\":\n",
    "                    df_treated.loc[outlier_idx, col] = (\n",
    "                        (df_treated[col].shift(1) + df_treated[col].shift(-1)) / 2\n",
    "                    ).loc[outlier_idx]\n",
    "                \n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown outlier treatment method: {method}\")\n",
    "        \n",
    "        return df_treated\n",
    "    \n",
    "    # ---------------- Test Data ----------------7\n",
    "    @staticmethod\n",
    "    def test_data():\n",
    "        \"\"\"\n",
    "        Generate a predefined test DataFrame containing sample OHLCV (Open, High, Low, Close, Volume) data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A pandas DataFrame with the following columns:\n",
    "            - date (datetime): Business dates from 2025-10-01 to 2025-10-28\n",
    "            - low (float): Daily low prices\n",
    "            - high (float): Daily high prices\n",
    "            - open (float): Daily opening prices\n",
    "            - close (float): Daily closing prices\n",
    "            - volume (int): Trading volumes\n",
    "\n",
    "        test_df = pd.DataFrame({\n",
    "            'date': [\n",
    "                '2025-10-01', '2025-10-02', '2025-10-03', '2025-10-06', '2025-10-07',\n",
    "                '2025-10-08', '2025-10-09', '2025-10-10', '2025-10-13', '2025-10-14',\n",
    "                '2025-10-15', '2025-10-16', '2025-10-17', '2025-10-20', '2025-10-21',\n",
    "                '2025-10-22', '2025-10-23', '2025-10-24', '2025-10-27', '2025-10-28'\n",
    "            ],\n",
    "            'low': [\n",
    "                98.37, 99.10, 101.25, 102.40, 103.55, 104.10, 105.00, 106.25, 107.00, 108.10,\n",
    "                108.50, 109.00, 110.20, 111.00, 111.50, 112.00, 112.80, 113.50, 114.10, 115.00\n",
    "            ],\n",
    "            'high': [\n",
    "                103.75, 104.50, 106.80, 107.95, 109.20, 110.00, 111.30, 112.50, 113.20, 114.50,\n",
    "                115.00, 116.20, 117.50, 118.00, 118.50, 119.20, 120.00, 120.50, 121.30, 122.00\n",
    "            ],\n",
    "            'open': [\n",
    "                100.50, 101.80, 103.40, 104.80, 105.60, 106.20, 107.15, 108.50, 109.10, 110.20,\n",
    "                110.80, 111.50, 112.40, 113.20, 113.80, 114.50, 115.20, 116.00, 116.50, 117.20\n",
    "            ],\n",
    "            'close': [\n",
    "                101.25, 102.40, 104.50, 105.90, 106.80, 107.50, 108.70, 109.80, 110.60, 111.50,\n",
    "                112.20, 112.90, 113.80, 114.50, 115.00, 115.80, 116.50, 117.00, 117.80, 118.50\n",
    "            ],\n",
    "            'volume': [\n",
    "                1711, 2378, 3200, 4100, 3850, 4500, 5000, 9750, 4900, 5100,\n",
    "                5300, 5500, 5700, 5900, 6000, 6200, 6400, 6500, 6700, 6900\n",
    "            ]\n",
    "        })\n",
    "        \"\"\"\n",
    "        test_df = pd.DataFrame({\n",
    "            'date': [\n",
    "                '2025-10-01', '2025-10-02', '2025-10-03', '2025-10-06', '2025-10-07',\n",
    "                '2025-10-08', '2025-10-09', '2025-10-10', '2025-10-13', '2025-10-14',\n",
    "                '2025-10-15', '2025-10-16', '2025-10-17', '2025-10-20', '2025-10-21',\n",
    "                '2025-10-22', '2025-10-23', '2025-10-24', '2025-10-27', '2025-10-28'\n",
    "            ],\n",
    "            'low': [\n",
    "                98.37, 99.10, 101.25, 102.40, 103.55, 104.10, 105.00, 106.25, 107.00, 108.10,\n",
    "                108.50, 109.00, 110.20, 111.00, 111.50, 112.00, 112.80, 113.50, 114.10, 115.00\n",
    "            ],\n",
    "            'high': [\n",
    "                103.75, 104.50, 106.80, 107.95, 109.20, 110.00, 111.30, 112.50, 113.20, 114.50,\n",
    "                115.00, 116.20, 117.50, 118.00, 118.50, 119.20, 120.00, 120.50, 121.30, 122.00\n",
    "            ],\n",
    "            'open': [\n",
    "                100.50, 101.80, 103.40, 104.80, 105.60, 106.20, 107.15, 108.50, 109.10, 110.20,\n",
    "                110.80, 111.50, 112.40, 113.20, 113.80, 114.50, 115.20, 116.00, 116.50, 117.20\n",
    "            ],\n",
    "            'close': [\n",
    "                101.25, 102.40, 104.50, 105.90, 106.80, 107.50, 108.70, 109.80, 110.60, 111.50,\n",
    "                112.20, 112.90, 113.80, 114.50, 115.00, 115.80, 116.50, 117.00, 117.80, 118.50\n",
    "            ],\n",
    "            'volume': [\n",
    "                1711, 2378, 3200, 4100, 3850, 4500, 5000, 9750, 4900, 5100,\n",
    "                5300, 5500, 5700, 5900, 6000, 6200, 6400, 6500, 6700, 6900\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "        return test_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
